{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlagents_envs.environment import UnityEnvironment as UE\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from collections import deque\n",
    "from dqn_agent import Agent\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_PATH = \"environment-MAC/en.app\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initialise customised Banana Collecter environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_env(ENV_PATH):\n",
    "    # env = UnityEnvironment(file_name=ENV_PATH)\n",
    "    env = UE(base_port=5004,file_name=ENV_PATH, seed=1, side_channels=[])\n",
    "    env.step()\n",
    "    # in this project, we are only using one agent, so we will only work on the first `brain` in the environmet\n",
    "    # get the default brain\n",
    "    # brain_name = env.brain_names[0]\n",
    "    brain_name = list(env.behavior_specs.keys())[0]\n",
    "    # brain = env.brains[brain_name]\n",
    "    brain = env.behavior_specs[brain_name]\n",
    "    return env, brain, brain_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = UE(file_name=ENV_PATH, seed=1, side_channels=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = env.behavior_specs.keys()\n",
    "# print(list(test)[0])\n",
    "# for t in test:\n",
    "#     print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brain_name = list(env.behavior_specs.keys())[0]\n",
    "# print(brain_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brain = env.behavior_specs[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0615 22:50:36.080380000 8670080512 fork_posix.cc:76]                  Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UnityMemory] Configuration Parameters - Can be set up in boot.config\n",
      "    \"memorysetup-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-cache-allocator-block-size=4194304\"\n",
      "    \"memorysetup-typetree-allocator-block-size=2097152\"\n",
      "    \"memorysetup-profiler-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-profiler-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-profiler-allocator-block-size=16777216\"\n",
      "    \"memorysetup-profiler-editor-allocator-block-size=1048576\"\n",
      "    \"memorysetup-temp-allocator-size-main=4194304\"\n",
      "    \"memorysetup-job-temp-allocator-block-size=2097152\"\n",
      "    \"memorysetup-job-temp-allocator-block-size-background=1048576\"\n",
      "    \"memorysetup-job-temp-allocator-reduction-small-platforms=262144\"\n",
      "    \"memorysetup-temp-allocator-size-background-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-job-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-preload-manager=262144\"\n",
      "    \"memorysetup-temp-allocator-size-nav-mesh-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-audio-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-cloud-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-gfx=262144\"\n"
     ]
    }
   ],
   "source": [
    "env, brain, brain_name = initialise_env(ENV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(brain_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先让他走几步直到需要交互\n",
    "# env.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The state space has `37` dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initialise the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BehaviorSpec(observation_specs=[ObservationSpec(shape=(128, 128, 3), dimension_property=(<DimensionProperty.TRANSLATIONAL_EQUIVARIANCE: 2>, <DimensionProperty.TRANSLATIONAL_EQUIVARIANCE: 2>, <DimensionProperty.NONE: 1>), observation_type=<ObservationType.DEFAULT: 0>, name='CameraSensor'), ObservationSpec(shape=(147,), dimension_property=(<DimensionProperty.NONE: 1>,), observation_type=<ObservationType.DEFAULT: 0>, name='RayPerceptionSensor-1'), ObservationSpec(shape=(147,), dimension_property=(<DimensionProperty.NONE: 1>,), observation_type=<ObservationType.DEFAULT: 0>, name='RayPerceptionSensor-2'), ObservationSpec(shape=(147,), dimension_property=(<DimensionProperty.NONE: 1>,), observation_type=<ObservationType.DEFAULT: 0>, name='RayPerceptionSensor-3'), ObservationSpec(shape=(0,), dimension_property=(<DimensionProperty.NONE: 1>,), observation_type=<ObservationType.DEFAULT: 0>, name='VectorSensor'), ObservationSpec(shape=(4,), dimension_property=(<DimensionProperty.NONE: 1>,), observation_type=<ObservationType.DEFAULT: 0>, name='VectorSensor_size4')], action_spec=ActionSpec(continuous_size=0, discrete_branches=(5,)))\n"
     ]
    }
   ],
   "source": [
    "spec = env.behavior_specs['My Behavior?team=0']\n",
    "print(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the environment\n",
    "#env_info = env.reset(train_mode=True)[brain_name]\n",
    "env_info = env.reset()\n",
    "#action_size = brain.vector_action_space_size\n",
    "#state_size = len(env_info.vector_observations[0])\n",
    "#agent = Agent(state_size=state_size, action_size=action_size, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(env_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_size = list(brain.action_spec)[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change\n",
    "# decision_steps.obs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ObservationSpec(shape=(128, 128, 3), dimension_property=(<DimensionProperty.TRANSLATIONAL_EQUIVARIANCE: 2>, <DimensionProperty.TRANSLATIONAL_EQUIVARIANCE: 2>, <DimensionProperty.NONE: 1>), observation_type=<ObservationType.DEFAULT: 0>, name='CameraSensor'), ObservationSpec(shape=(147,), dimension_property=(<DimensionProperty.NONE: 1>,), observation_type=<ObservationType.DEFAULT: 0>, name='RayPerceptionSensor-1'), ObservationSpec(shape=(147,), dimension_property=(<DimensionProperty.NONE: 1>,), observation_type=<ObservationType.DEFAULT: 0>, name='RayPerceptionSensor-2'), ObservationSpec(shape=(147,), dimension_property=(<DimensionProperty.NONE: 1>,), observation_type=<ObservationType.DEFAULT: 0>, name='RayPerceptionSensor-3'), ObservationSpec(shape=(0,), dimension_property=(<DimensionProperty.NONE: 1>,), observation_type=<ObservationType.DEFAULT: 0>, name='VectorSensor'), ObservationSpec(shape=(4,), dimension_property=(<DimensionProperty.NONE: 1>,), observation_type=<ObservationType.DEFAULT: 0>, name='VectorSensor_size4')]\n"
     ]
    }
   ],
   "source": [
    "print(brain.observation_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_size = len(brain.observation_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ObservationSpec(shape=(128, 128, 3), dimension_property=(<DimensionProperty.TRANSLATIONAL_EQUIVARIANCE: 2>, <DimensionProperty.TRANSLATIONAL_EQUIVARIANCE: 2>, <DimensionProperty.NONE: 1>), observation_type=<ObservationType.DEFAULT: 0>, name='CameraSensor'),\n",
       " ObservationSpec(shape=(147,), dimension_property=(<DimensionProperty.NONE: 1>,), observation_type=<ObservationType.DEFAULT: 0>, name='RayPerceptionSensor-1'),\n",
       " ObservationSpec(shape=(147,), dimension_property=(<DimensionProperty.NONE: 1>,), observation_type=<ObservationType.DEFAULT: 0>, name='RayPerceptionSensor-2'),\n",
       " ObservationSpec(shape=(147,), dimension_property=(<DimensionProperty.NONE: 1>,), observation_type=<ObservationType.DEFAULT: 0>, name='RayPerceptionSensor-3'),\n",
       " ObservationSpec(shape=(0,), dimension_property=(<DimensionProperty.NONE: 1>,), observation_type=<ObservationType.DEFAULT: 0>, name='VectorSensor'),\n",
       " ObservationSpec(shape=(4,), dimension_property=(<DimensionProperty.NONE: 1>,), observation_type=<ObservationType.DEFAULT: 0>, name='VectorSensor_size4')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain.observation_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state_size = len(env_info.vector_observations[0])\n",
    "# state size 要改\n",
    "agent = Agent(state_size=state_size, action_size=action_size, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(x):\n",
    "    \"\"\" plots first ncols images in a batch \"\"\"\n",
    "    x = x.squeeze(1).T\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(20, 20))\n",
    "    ax.imshow(x, cmap=\"Greys\")\n",
    "    ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.transforms as transforms\n",
    "actions = []\n",
    "for act in range(5):\n",
    "    actions.append(spec.action_spec.empty_action(1))\n",
    "    actions[act].add_discrete(np.int32([[act]]))\n",
    "stop = actions[0]\n",
    "forward = actions[1]\n",
    "backward = actions[2]\n",
    "turn_right = actions[3]\n",
    "turn_left = actions[4]\n",
    "def train_dqn(agent, n_episodes=2, max_t=20, eps_start=1.0, eps_end=0.1, eps_decay=0.99):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    rewards =0\n",
    "    reward =0\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        decision_steps, terminal_steps = env.get_steps(brain_name)\n",
    "#         state = np.moveaxis(decision_steps.obs[0], -1, 0)\n",
    "        ray_sensor_1 = decision_steps.obs[1]\n",
    "#         print(ray_sensor_1.shape)\n",
    "        ray_sensor_2 = decision_steps.obs[2]\n",
    "        ray_sensor_3 = decision_steps.obs[3]\n",
    "        print(ray_sensor_3.shape)\n",
    "#         print(ray_sensor_2.shape)\n",
    "        state = np.concatenate((ray_sensor_1, ray_sensor_2, ray_sensor_3), axis=1)\n",
    "#         print(state)\n",
    "        print(state.shape)\n",
    "#         print(decision_steps.obs[2])\n",
    "#         print(decision_steps.obs[2].shape)\n",
    "        tracked_agent = -1\n",
    "        done = False\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            if tracked_agent == -1 and len(decision_steps) >= 1:\n",
    "                tracked_agent = decision_steps.agent_id[0]\n",
    "#             show_images(state)\n",
    "            action = agent.act(state, eps)\n",
    "            env.set_actions(brain_name, actions[action])\n",
    "            env.step()\n",
    "            decision_steps, terminal_steps = env.get_steps(brain_name)\n",
    "            \n",
    "#             next_state = np.moveaxis(decision_steps.obs[0], -1, 0)   # get the next state\n",
    "            ray_sensor_1 = decision_steps.obs[1]\n",
    "            ray_sensor_2 = decision_steps.obs[2]\n",
    "            ray_sensor_3 = decision_steps.obs[3]\n",
    "            next_state = np.concatenate((ray_sensor_1, ray_sensor_2, ray_sensor_3), axis=1)\n",
    "            if tracked_agent in decision_steps:# The agent requested a decision\n",
    "                reward = decision_steps[tracked_agent].reward  # get the reward\n",
    "                agent.step(state, action, reward, next_state, False)\n",
    "            if tracked_agent in terminal_steps: # The agent terminated its episode\n",
    "                rewards = terminal_steps[tracked_agent].reward# get the reward\n",
    "                agent.step(state, action, reward, next_state, True)\n",
    "                env.reset()\n",
    "                break\n",
    "            state = next_state\n",
    "            print(reward)\n",
    "            score += reward\n",
    "            \n",
    "        \n",
    "        scores_window.append(score)       # save most recent score\n",
    "#         print(scores_window)\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 50 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "            print('saved temporary learned weight')\n",
    "#         if np.mean(scores_window)>=500.0:\n",
    "#             print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "#             torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "#             print('agent done training')\n",
    "#             break\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-1.0\n",
      "0.0\n",
      "-1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 1\tAverage Score: -3.00(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 2\tAverage Score: -2.00(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "10.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 3\tAverage Score: 2.00(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "-1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 4\tAverage Score: 1.00(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 5\tAverage Score: 0.80(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 6\tAverage Score: 0.67(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 7\tAverage Score: 0.57(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 8\tAverage Score: 0.50(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 9\tAverage Score: 0.44(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 10\tAverage Score: 0.40(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 11\tAverage Score: 0.36(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "-1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 12\tAverage Score: 0.25(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 13\tAverage Score: 0.23(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 14\tAverage Score: 0.21(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 15\tAverage Score: 0.20(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 16\tAverage Score: 0.19(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-1.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 17\tAverage Score: 0.12(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-1.0\n",
      "-1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 18\tAverage Score: 0.00(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 19\tAverage Score: 0.00(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 20\tAverage Score: 0.00(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 21\tAverage Score: 0.00(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 22\tAverage Score: 0.00(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 23\tAverage Score: 0.00(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 24\tAverage Score: 0.00(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 25\tAverage Score: 0.00(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 26\tAverage Score: 0.00(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 27\tAverage Score: 0.00(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 28\tAverage Score: 0.00(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 29\tAverage Score: 0.00(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 30\tAverage Score: 0.00(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 31\tAverage Score: 0.00(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "10.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 32\tAverage Score: 0.31(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 33\tAverage Score: 0.30(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 34\tAverage Score: 0.29(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 35\tAverage Score: 0.29(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 36\tAverage Score: 0.28(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 37\tAverage Score: 0.27(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 38\tAverage Score: 0.26(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "10.0\n",
      "0.0\n",
      "Episode 39\tAverage Score: 0.49(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 40\tAverage Score: 0.42(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "-1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-1.0\n",
      "Episode 41\tAverage Score: 0.34(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 42\tAverage Score: 0.33(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 43\tAverage Score: 0.33(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 44\tAverage Score: 0.32(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 45\tAverage Score: 0.31(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 46\tAverage Score: 0.30(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-1.0\n",
      "0.0\n",
      "0.0\n",
      "-1.0\n",
      "Episode 47\tAverage Score: 0.23(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 48\tAverage Score: 0.21(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "-1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 49\tAverage Score: 0.14(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "-1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 50\tAverage Score: 0.10\n",
      "saved temporary learned weight\n",
      "(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 51\tAverage Score: 0.10(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 52\tAverage Score: 0.10(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 53\tAverage Score: 0.09(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 54\tAverage Score: 0.09(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 55\tAverage Score: 0.09(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 56\tAverage Score: 0.09(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 57\tAverage Score: 0.09(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 58\tAverage Score: 0.09(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 59\tAverage Score: 0.08(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "10.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 60\tAverage Score: 0.25(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 61\tAverage Score: 0.25(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 62\tAverage Score: 0.24(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 63\tAverage Score: 0.24(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 64\tAverage Score: 0.23(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 65\tAverage Score: 0.23(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 66\tAverage Score: 0.23(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 67\tAverage Score: 0.22(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 68\tAverage Score: 0.22(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 69\tAverage Score: 0.22(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 70\tAverage Score: 0.21(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 71\tAverage Score: 0.21(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Episode 72\tAverage Score: 0.21(1, 147)\n",
      "(1, 441)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "ename": "UnityCommunicatorStoppedException",
     "evalue": "Communicator has exited.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnityCommunicatorStoppedException\u001b[0m         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p2/fj_ptp_x055gqt839fj3ws6m0000gn/T/ipykernel_93804/4241999667.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     agent.qnetwork_local.load_state_dict(torch.load('checkpoint.pth'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/p2/fj_ptp_x055gqt839fj3ws6m0000gn/T/ipykernel_93804/624143800.py\u001b[0m in \u001b[0;36mtrain_dqn\u001b[0;34m(agent, n_episodes, max_t, eps_start, eps_end, eps_decay)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mdecision_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/mlagents_envs/timers.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mhierarchical_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/mlagents_envs/environment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexchange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll_process\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mUnityCommunicatorStoppedException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Communicator has exited.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_behavior_specs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mrl_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrl_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnityCommunicatorStoppedException\u001b[0m: Communicator has exited."
     ]
    }
   ],
   "source": [
    "# if os.path.isfile('./checkpoint.pth'):\n",
    "#     # load the weights from file\n",
    "#     agent.qnetwork_local.load_state_dict(torch.load('checkpoint.pth'))\n",
    "    \n",
    "scores = train_dqn(agent, n_episodes=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Plot performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Watch a trained agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def watch_banana_agent(agent, env, n_episodes=4, n_steps=300):\n",
    "\n",
    "                                   \n",
    "    \n",
    "#     for episode in range(n_episodes):\n",
    "        \n",
    "#         env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "#         state = env_info.vector_observations[0]            # get the current state\n",
    "#         score = 0                                          # initialize the score\n",
    "        \n",
    "#         for step in range(n_steps):\n",
    "\n",
    "#             action = agent.act(state)                 # select an action\n",
    "#             env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "#             next_state = env_info.vector_observations[0]   # get the next state\n",
    "#             reward = env_info.rewards[0]                   # get the reward\n",
    "#             done = env_info.local_done[0]                  # see if episode has finished\n",
    "#             score += reward                                # update the score\n",
    "#             state = next_state                             # roll over the state to next time step\n",
    "#             if done:                                       # exit loop if episode finished\n",
    "#                 break\n",
    "\n",
    "#         print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "reset() got an unexpected keyword argument 'train_mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p2/fj_ptp_x055gqt839fj3ws6m0000gn/T/ipykernel_67920/1660049170.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwatch_banana_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/p2/fj_ptp_x055gqt839fj3ws6m0000gn/T/ipykernel_67920/2633861598.py\u001b[0m in \u001b[0;36mwatch_banana_agent\u001b[0;34m(agent, env, n_episodes, n_steps)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepisode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0menv_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# reset the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_observations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m            \u001b[0;31m# get the current state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m                                          \u001b[0;31m# initialize the score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: reset() got an unexpected keyword argument 'train_mode'"
     ]
    }
   ],
   "source": [
    "# watch_banana_agent(agent, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
